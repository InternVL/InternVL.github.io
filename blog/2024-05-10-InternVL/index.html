<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <!-- Begin Jekyll SEO tag v2.8.0 -->
        <title>InternVL 1.0-1.3: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks| InternVL</title>
        <meta name="generator" content="Jekyll v3.9.4"/>
        <meta property="og:title" content="InternVL 1.0-1.3: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks"/>
        <meta name="author" content="chenzhe"/>
        <meta property="og:locale" content="en_US"/>
        <meta name="description" content="LLaVA team presents LLaVA-NeXT, with improved reasoning, OCR, and world knowledge. LLaVA-NeXT even exceeds Gemini Pro on several benchmarks."/>
        <meta property="og:description" content="LLaVA team presents LLaVA-NeXT, with improved reasoning, OCR, and world knowledge. LLaVA-NeXT even exceeds Gemini Pro on several benchmarks."/>
        <link rel="canonical" href="https://internvl.github.io/blog/2024-05-10-InternVL/"/>
        <meta property="og:url" content="https://internvl.github.io/blog/2024-05-10-InternVL/"/>
        <meta property="og:site_name" content="InternVL"/>
        <meta property="og:type" content="article"/>
        <meta property="article:published_time" content="2024-01-30T12:33:38-06:00"/>
        <meta name="twitter:card" content="summary"/>
        <meta property="twitter:title" content="InternVL 1.0-1.3: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks"/>
        <script type="application/ld+json">
            {
                "@context": "https://schema.org",
                "@type": "BlogPosting",
                "author": {
                    "@type": "Person",
                    "name": "chenzhe"
                },
                "dateModified": "2024-01-30T12:33:38-06:00",
                "datePublished": "2024-01-30T12:33:38-06:00",
                "description": "InternVL 1.0-1.3: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks",
                "headline": "InternVL 1.0-1.3: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks",
                "mainEntityOfPage": {
                    "@type": "WebPage",
                    "@id": "https://internvl.github.io/blog/2024-05-10-InternVL/"
                },
                "url": "https://internvl.github.io/blog/2024-05-10-InternVL/"
            }</script>
        <!-- End Jekyll SEO tag -->
        <link rel="stylesheet" href="/blog/assets/main.css">
        <link type="application/atom+xml" rel="alternate" href="https://llava-vl.github.io/blog/feed.xml" title="LLaVA"/>
    </head>
    <body>
        <header class="site-header" role="banner">
            <div class="wrapper">
                <a class="site-title" rel="author" href="/blog/">InternVL</a>
                <nav class="site-nav">
                    <input type="checkbox" id="nav-trigger" class="nav-trigger"/>
                    <label for="nav-trigger">
                        <span class="menu-icon">
                            <svg viewBox="0 0 18 15" width="18px" height="15px">
                                <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
                            </svg>
                        </span>
                    </label>
                    <div class="trigger"></div>
                </nav>
            </div>
        </header>
        <main class="page-content" aria-label="Content">
            <div class="wrapper">
                <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
                    <header class="post-header">
                        <h1 class="post-title p-name" itemprop="name headline">InternVL 1.0-1.3: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks</h1>
                        <p class="post-meta">
                            <time class="dt-published" datetime="2024-01-30T12:33:38-06:00" itemprop="datePublished">May 10, 2024
      </time>
                            • 
                            <span itemprop="author" itemscope itemtype="http://schema.org/Person">
                                <span class="p-author h-card" itemprop="name">chenzhe</span>
                            </span>
                        </p>
                    </header>
                    <div class="post-content e-content" itemprop="articleBody">
                        <!-- 插入Markdown转换后的HTML内容 -->
                        <h1>InternVL's Blog</h1>

                        <h2>InternVL-Chat-V1.2-Plus</h2>

                        <blockquote>
                            <p>Date: 2024/02/21<br>Developed by: Zhe Chen, Weiyun Wang, Wenhai Wang, Erfei Cui, Zhangwei Gao, Xizhou Zhu, Lewei Lu, Tong Lu, Yu Qiao, Jifeng Dai</p>
                        </blockquote>

                        <p><a href="https://huggingface.co/OpenGVLab/InternVL-Chat-V1-2-Plus">InternVL-Chat-V1.2-Plus</a> uses the same model architecture as InternVL-Chat-V1.2, but the difference lies in the SFT dataset. InternVL-Chat-V1.2 only utilizes an SFT dataset with 1.2M samples, while our plus version employs an SFT dataset with 12M samples.</p>

                        <h3>Performance</h3>

                        <p>* Proprietary Model † Training Set Observed</p>

                        <table>
                            <thead>
                                <tr>
                                    <th>name</th>
                                    <th>image size</th>
                                    <th>MMMU<br>(val)</th>
                                    <th>MMMU<br>(test)</th>
                                    <th>MathVista<br>(testmini)</th>
                                    <th>MMB<br>(test)</th>
                                    <th>MMB−CN<br>(test)</th>
                                    <th>MMVP</th>
                                    <th>MME</th>
                                    <th>ScienceQA<br>(image)</th>
                                    <th>POPE</th>
                                    <th>TextVQA<br>(val)</th>
                                    <th>SEEDv1<br>(image)</th>
                                    <th>VizWiz<br>(test)</th>
                                    <th>GQA<br>(test)</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>GPT-4V*</td>
                                    <td>unknown</td>
                                    <td>56.8</td>
                                    <td>55.7</td>
                                    <td>49.9</td>
                                    <td>77.0</td>
                                    <td>74.4</td>
                                    <td>38.7</td>
                                    <td>1409/517</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>78.0</td>
                                    <td>71.6</td>
                                    <td>-</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Gemini Ultra*</td>
                                    <td>unknown</

td>
                                    <td>59.4</td>
                                    <td>-</td>
                                    <td>53.0</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>82.3</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Gemini Pro*</td>
                                    <td>unknown</td>
                                    <td>47.9</td>
                                    <td>-</td>
                                    <td>45.2</td>
                                    <td>73.6</td>
                                    <td>74.3</td>
                                    <td>40.7</td>
                                    <td>1497/437</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>74.6</td>
                                    <td>70.7</td>
                                    <td>-</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Qwen−VL−Plus*</td>
                                    <td>unknown</td>
                                    <td>45.2</td>
                                    <td>40.8</td>
                                    <td>43.3</td>
                                    <td>67.0</td>
                                    <td>70.7</td>
                                    <td>-</td>
                                    <td>1681/502</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>78.9</td>
                                    <td>65.7</td>
                                    <td>-</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Qwen−VL−Max*</td>
                                    <td>unknown</td>
                                    <td>51.4</td>
                                    <td>46.8</td>
                                    <td>51.0</td>
                                    <td>77.6</td>
                                    <td>75.7</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>79.5</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td></td>
                                    <td></td>
                                    <td></td>
                                    <td></td>
                                    <td></td>
                                    <td></td>
                                    <td></td>
                                    <td></td>
                                    <td></td>
                                    <td></td>
                                    <td></td>
                                    <td></td>
                                    <td></td>
                                    <td></td>
                                    <td></td>
                                </tr>
                                <tr>
                                    <td>LLaVA−NEXT−34B</td>
                                    <td>672x672</td>
                                    <td>51.1</td>
                                    <td>44.7</td>
                                    <td>46.5</td>
                                    <td>79.3</td>
                                    <td>79.0</td>
                                    <td>-</td>
                                    <td>1631/397</td>
                                    <td>81.8</td>
                                    <td>87.7</td>
                                    <td>69.5</td>
                                    <td>75.9</td>
                                    <td>63.8</td>
                                    <td>67.1†</td>
                                </tr>
                                <tr>
                                    <td>InternVL−Chat−V1.2</td>
                                    <td>448x448</td>
                                    <td>51.6</td>
                                    <td>46.2</td>
                                    <td>47.7</td>
                                    <td>82.2</td>
                                    <td>81.2</td>
                                    <td>56.7</td>
                                    <td>1687/489</td>
                                    <td>83.3</td>
                                    <td>88.0</td>
                                    <td>72.5</td>
                                    <td>75.6</td>
                                    <td>60.0</td>
                                    <td>64.0†</td>
                                </tr>
                                <tr>
                                    <td>InternVL−Chat−V1.2−Plus</td>
                                    <td>448x448</td>
                                    <td>50.3</td>
                                    <td>45.6</td>
                                    <td>59.9</td>
                                    <td>83.8</td>
                                    <td>82.0</td>
                                    <td>58.7</td>
                                    <td>1625/553</td>
                                    <td>98.1†</td>
                                    <td>88.7</td>
                                    <td>74.1†</td>
                                    <td>76.4</td>
                                    <td>59.5</td>
                                    <td>66.9†</td>
                                </tr>
                            </tbody>
                        </table>

                        <ul>
                            <li>MMBench results are collected from the <a href="https://mmbench.opencompass.org.cn/leaderboard">leaderboard</a>.</li>
                            <li>Update (2024-04-21): We have fixed a bug in the evaluation code, and the TextVQA results have been corrected.</li>
                        </ul>

                        <h2>InternVL-Chat-V1.2</h2>

                        <blockquote>
                            <p>Date: 2024/02/12<br>Developed by: Zhe Chen, Weiyun Wang, Wenhai Wang, Erfei Cui, Zhangwei Gao, Xizhou Zhu, Lewei Lu, Tong Lu, Yu Qiao, Jifeng Dai</p>
                        </blockquote>

                        <p>We are excited to introduce InternVL-Chat-V1.2. Inspired by <a href="https://llava-vl.github.io/blog/2024-01-30-llava-next/">LLaVA-NeXT-34B</a>, we have also adopted <a href="https://huggingface.co/NousResearch/Nous-Hermes-2-Yi-34B">Nous-Hermes-2-Yi-34B</a> as the language model. Below is the pipeline.</p>

                        <p><img width="650" alt="image" src="images/Intern1_2_1.png"></p>

                        <p>From the experimental results, <strong>we've observed that a stronger language model (34B) can better leverage the powerful capabilities of our vision foundation model (<a href="https://huggingface.co/OpenGVLab/InternViT-6B-448px-V1-2">InternViT-6B</a>).</strong></p>

                        <p>For better training reproducibility, we follow the minimalist design and data efficiency similar to LLaVA-NeXT. To reduce training costs, we provide a pre-trained MLP projector and only employ around 1 million visual instruction tuning samples for SFT. Our model has a total of 40 billion parameters and can be trained within 1.5 days using 32 A100 GPUs. The code, data, and model will be made publicly available.</p>

                        <h3>Data Preparation</h3>

                        <p>Inspired by LLaVA-NeXT, we adopted a data-efficient SFT strategy to train InternVL-Chat-V1.2, utilizing approximately 1.2M of visual instruction tuning samples in total, all of which are fully open-source. In a macro sense, we build upon <a href="https://github.com/InternLM/InternLM-XComposer/blob/main/projects/ShareGPT4V/docs/Data.md#prepare-images">ShareGPT-4V</a> and additionally integrate <a href="https://huggingface.co/datasets/openbmb/llava_zh">LLaVA-ZH</a>, <a href="https://github.com/kushalkafle/DVQA_dataset">DVQA</a>, <a href="https://github.com/vis-nlp/ChartQA">ChartQA</a>, <a href="https://allenai.org/data/diagrams">AI2D</a>, <a href="https://www.docvqa.org/datasets">DocVQA</a>, <a href="https://github.com/SCNU203/GeoQA-Plus">GeoQA+</a>, and <a href="https://huggingface.co/datasets/naver-clova-ix/synthdog-en">SynthDoG-EN</a>. Most of the data remains consistent with LLaVA-NeXT.</p>


                        <h3>Performance</h3>

                        <p>* Proprietary Model</p>

                        <table>
                            <thead>
                                <tr>
                                    <th>name</th>
                                    <th>image size</th>
                                    <th>MMMU<br>(val)</th>
                                    <th>MMMU<br>(test)</th>
                                    <th>

MathVista<br>(testmini)</th>
                                    <th>MMB<br>(test)</th>
                                    <th>MMB−CN<br>(test)</th>
                                    <th>MMVP</th>
                                    <th>MME</th>
                                    <th>ScienceQA<br>(image)</th>
                                    <th>POPE</th>
                                    <th>TextVQA</th>
                                    <th>SEEDv1<br>(image)</th>
                                    <th>VizWiz<br>(test)</th>
                                    <th>GQA<br>(test)</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>GPT-4V*</td>
                                    <td>unknown</td>
                                    <td>56.8</td>
                                    <td>55.7</td>
                                    <td>49.9</td>
                                    <td>77.0</td>
                                    <td>74.4</td>
                                    <td>38.7</td>
                                    <td>1409/517</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>78.0</td>
                                    <td>71.6</td>
                                    <td>-</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Gemini Ultra*</td>
                                    <td>unknown</td>
                                    <td>59.4</td>
                                    <td>-</td>
                                    <td>53.0</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>82.3</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Gemini Pro*</td>
                                    <td>unknown</td>
                                    <td>47.9</td>
                                    <td>-</td>
                                    <td>45.2</td>
                                    <td>73.6</td>
                                    <td>74.3</td>
                                    <td>40.7</td>
                                    <td>1497/437</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>74.6</td>
                                    <td>70.7</td>
                                    <td>-</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Qwen-VL-Plus*</td>
                                    <td>unknown</td>
                                    <td>45.2</td>
                                    <td>40.8</td>
                                    <td>43.3</td>
                                    <td>67.0</td>
                                    <td>70.7</td>
                                    <td>-</td>
                                    <td>1681/502</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>78.9</td>
                                    <td>65.7</td>
                                    <td>-</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Qwen-VL-Max*</td>
                                    <td>unknown</td>
                                    <td>51.4</td>
                                    <td>46.8</td>
                                    <td>51.0</td>
                                    <td>77.6</td>
                                    <td>75.7</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>79.5</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td></td>
                                    <td></td>
                                    <td></td>
                                    <td></td>
                                    <td></td>
                                    <td></td>
                                    <td></td>
                                    <td></td>
                                    <td></td>
                                    <td></td>
                                    <td></td>
                                    <td></td>
                                    <td></td>
                                    <td></td>
                                    <td></td>
                                </tr>
                                <tr>
                                    <td>LLaVA−NEXT−34B</td>
                                    <td>672x672</td>
                                    <td>51.1</td>
                                    <td>44.7</td>
                                    <td>46.5</td>
                                    <td>79.3</td>
                                    <td>79.0</td>
                                    <td>-</td>
                                    <td>1631/397</td>
                                    <td>81.8</td>
                                    <td>87.7</td>
                                    <td>69.5</td>
                                    <td>75.9</td>
                                    <td>63.8</td>
                                    <td>67.1</td>
                                </tr>
                                <tr>
                                    <td>InternVL−Chat−V1.2</td>
                                    <td>448x448</td>
                                    <td>51.6</td>
                                    <td>46.2</td>
                                    <td>47.7</td>
                                    <td>82.2</td>
                                    <td>81.2</td>
                                    <td>56.7</td>
                                    <td>1687/489</td>
                                    <td>83.3</td>
                                    <td>88.0</td>
                                    <td>72.5</td>
                                    <td>75.6</td>
                                    <td>60.0</td>
                                    <td>64.0</td>
                                </tr>
                            </tbody>
                        </table>

                        <ul>
                            <li>MMBench results are collected from the <a href="https://mmbench.opencompass.org.cn/leaderboard">leaderboard</a>.</li>
                            <li>In most benchmarks, InternVL-Chat-V1.2 achieves better performance than LLaVA-NeXT-34B.</li>
                            <li>Update (2024-04-21): We have fixed a bug in the evaluation code, and the TextVQA result has been corrected to 72.5.</li>
                        </ul>

                        <h3>Training (SFT)</h3>

                        <p>We provide <a href="./internvl_chat/shell/hermes2_yi34b/internvl_chat_v1_2_hermes2_yi34b_448_res_finetune.sh">slurm scripts</a> for multi-node multi-GPU training. You can use either 32 or 64 GPUs to train this model. If you use 64 GPUs, training will take approximately 18 hours.</p>


                        <p>The hyperparameters used for finetuning are listed in the following table.</p>

                        <table>
                            <thead>
                                <tr>
                                    <th>Hyperparameter</th>
                                    <th>Trainable Param</th>
                                    <th>Global Batch Size</th>
                                    <th>Learning rate</th>
                                    <th>Epochs</th>
                                    <th>Max length</th>
                                    <th>Weight decay</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>InternVL-Chat-V1.2</td>
                                    <td>40B (full model)</td>
                                    <td>512</td>
                                    <td>1e-5</td>
                                    <td>1</td>
                                    <td>2048</td>
                                    <td>0.05</td>
                                </tr>
                            </tbody>
                        </table>

                        <h2>InternVL-Chat-V1.1</h2>

                        <blockquote>
                            <p>Date: 2024/01/24<br>Developed by: Zhe Chen, Wenhai Wang, Xizhou Zhu, Lewei Lu, Tong Lu, Yu Qiao, Jifeng Dai</p>
                        </blockquote>

                        <p>We released <a href="https://huggingface.co/OpenGVLab/InternVL-Chat-V1-1">InternVL-Chat-V1.1</a>, featuring a structure similar to LLaVA, including a ViT, an MLP projector, and an LLM. In this version, we explored increasing the resolution to 448x448, enhancing OCR capabilities, and improving support for Chinese conversations. Below is an example of the improved capabilities.</p>

                        <p><img width="650" alt="image" src="https://github.com/OpenGVLab/InternVL/assets/8529570/0e60912e-c52b-46fa-bd61-5f94a221d1fc"></p>

                        <h2>InternVL</h2>

                        <blockquote>
                            <p>Date: 2023/12/12<br>Developed by: Zhe Chen, Jiannan Wu, Wenhai Wang, Weijie Su, Guo Chen, Sen Xing, Muyan Zhong, Qinglong Zhang, Xizhou Zhu, Lewei Lu, Bin Li, Ping Luo, Tong Lu, Yu Qiao, Jifeng Dai</p>
                        </blockquote>

                        <h3>What is InternVL?</

h3>

                        <p>We released <a href="https://huggingface.co/collections/OpenGVLab/internvl-65b92d6be81c86166ca0dde4">InternVL</a>, scaling up the ViT to 6B parameters and aligning it with LLM. It is the largest open-source vision/vision-language foundation model (14B) to date, achieving 32 state-of-the-art performances on a wide range of tasks such as visual perception, cross-modal retrieval, multimodal dialogue, etc.</p>

                        <p><img width="950" alt="image" src="https://github.com/OpenGVLab/InternVL/assets/23737120/7cd8c1d5-99e7-4b62-b70a-e73d4838daa8"></p>

                        <h3>How is InternVL trained?</h3>

                        <p>The training strategy of InternVL consists of three progressive stages, including vision-language contrastive training, vision-language generative training, and supervised fine-tuning. These stages effectively leverage public data from diverse sources, ranging from noisy image-text pairs on the web to high-quality caption, VQA, and multi-modal dialogue datasets.</p>

                        <p><img width="700" alt="image" src="https://github.com/OpenGVLab/InternVL/assets/8529570/a060ba07-faf7-45db-8a4c-a3a343141569"></p>

                        <h3>What can InternVL do?</h3>

                        <p>InternVL is a “Swiss Army Knife” Model. By flexibly combining the vision encoder and the language middleware, InternVL can support various vision or vision-language tasks, including</p>

                        <details>
                            <summary>Visual Perception (click to expand)</summary>
                            <ul>
                                <li>Linear-Probe Image Classification
                                <p>ViT-22B uses the private JFT-3B dataset.</p>
                                <table>
                                    <thead>
                                        <tr>
                                            <th>method</th>
                                            <th>#param</th>
                                            <th>IN-1K</th>
                                            <th>IN-ReaL</th>
                                            <th>IN-V2</th>
                                            <th>IN-A</th>
                                            <th>IN-R</th>
                                            <th>IN-Sketch</th>
                                        </tr>
                                    </thead>
                                    <tbody>
                                        <tr>
                                            <td>OpenCLIP-G</td>
                                            <td>1.8B</td>
                                            <td>86.2</td>
                                            <td>89.4</td>
                                            <td>77.2</td>
                                            <td>63.8</td>
                                            <td>87.8</td>
                                            <td>66.4</td>
                                        </tr>
                                        <tr>
                                            <td>DINOv2-g</td>
                                            <td>1.1B</td>
                                            <td>86.5</td>
                                            <td>89.6</td>
                                            <td>78.4</td>
                                            <td>75.9</td>
                                            <td>78.8</td>
                                            <td>62.5</td>
                                        </tr>
                                        <tr>
                                            <td>EVA-01-CLIP-g</td>
                                            <td>1.1B</td>
                                            <td>86.5</td>
                                            <td>89.3</td>
                                            <td>77.4</td>
                                            <td>70.5</td>
                                            <td>87.7</td>
                                            <td>63.1</td>
                                        </tr>
                                        <tr>
                                            <td>MAWS-ViT-6.5B</td>
                                            <td>6.5B</td>
                                            <td>87.8</td>
                                            <td>-</td>
                                            <td>-</td>
                                            <td>-</td>
                                            <td>-</td>
                                            <td>-</td>
                                        </tr>
                                        <tr>
                                            <td>ViT-22B*</td>
                                            <td>21.7B</td>
                                            <td>89.5</td>
                                            <td>90.9</td>
                                            <td>83.2</td>
                                            <td>83.8</td>
                                            <td>87.4</td>
                                            <td>−</td>
                                        </tr>
                                        <tr>
                                            <td>InternViT-6B (ours)</td>
                                            <td>5.9B</td>
                                            <td>88.2</td>
                                            <td>90.4</td>
                                            <td>79.9</td>
                                            <td>77.5</td>
                                            <td>89.8</td>
                                            <td>69.1</td>
                                        </tr>
                                    </tbody>
                                </table>
                                <li>Semantic Segmentation</li>
                                <table>
                                    <thead>
                                        <tr>
                                            <th>method</th>
                                            <th>decoder</th>
                                            <th>#param (train/total)</th>
                                            <th>crop size</th>
                                            <th>mIoU</th>
                                        </tr>
                                    </thead>
                                    <tbody>
                                        <tr>
                                            <td>OpenCLIP-G (frozen)</td>
                                            <td>Linear</td>
                                            <td>0.3M / 1.8B</td>
                                            <td>512</td>
                                            <td>39.3</td>
                                        </tr>
                                        <tr>
                                            <td>ViT-22B (frozen)</td>
                                            <td>Linear</td>
                                            <td>0.9M / 21.7B</td>
                                            <td>504</td>
                                            <td>34.6</td>
                                        </tr>
                                        <tr>
                                            <td>InternViT-6B (frozen)</td>
                                            <td>Linear</td>
                                            <td>0.5M / 5.9B</td>
                                            <td>504</td>
                                            <td>47.2 (+12.6)</td>
                                        </tr>
                                        <tr>
                                            <td>ViT-22B (frozen)</td>
                                            <td>UperNet</td>
                                            <td>0.8B / 22.5B</td>
                                            <td>504</td>
                                            <td>52.7</td>
                                        </tr>
                                        <tr>
                                            <td>InternViT-6B (frozen)</td>
                                            <td>UperNet</td>
                                            <td>0.4B / 6.3B</td>
                                            <td>504</td>
                                            <td>54.9 (+2.2)</td>
                                        </tr>
                                        <tr>
                                            <td>ViT-22B</td>
                                            <td>UperNet</td>
                                            <td>22.5B / 22.5B</td>
                                            <td>504</td>
                                            <td>55.3</td>
                                        </tr>
                                        <tr>
                                            <td>InternViT-6B</td>
                                            <td>UperNet</td>
                                            <td>6.3B / 6.3B</td>
                                            <td>504</td>
                                            <td>58.9 (+3.6)</td>
                                        </tr>
                                    </tbody>
                                </table>
                                <li>Zero-Shot Image Classification</li>
                                <table>
                                    <thead>
                                        <tr>
                                            <th>method</th>
                                            <th>IN-1K</th>
                                            <th>IN-A</th>
                                            <th>IN-R</th>
                                            <th>IN-V2</th>
                                            <th>IN-Sketch</th>
                                            <th>ObjectNet</th>
                                        </tr>
                                    </thead>
                                    <tbody>
                                        <tr>
                                            <td>OpenCLIP-G</td>
                                            <td>80.1</td>
                                            <td>69.3</td>
                                            <td>92.1</td>
                                            <td>73.6</td>
                                            <td>68.9</td>
                                            <td>73.0</td>
                                        </tr>
                                        <tr>
                                            <td>EVA-02-CLIP-E+</td>
                                            <td>82.0</td>
                                            <td>82.1</td>
                                            <td>94.5</td>
                                            <td>75.7</td>
                                            <td>71.6</td>
                                            <td>79.6</td>
                                        </tr>
                                        <tr>
                                            <td>ViT-22B*</td>
                                            <td>85.9</td>
                                            <td>90.1</td>
                                            <td>96.0</td>
                                            <td>80.9</td>
                                            <td>−</td>
                                            <td>87.6</td>
                                        </tr>
                                        <tr>
                                            <td>InternVL-C (ours)</td>
                                            <

td>83.2</td>
                                            <td>83.8</td>
                                            <td>95.5</td>
                                            <td>77.3</td>
                                            <td>73.9</td>
                                            <td>80.6</td>
                                        </tr>
                                    </tbody>
                                </table>
                                <li>Multilingual Zero-Shot Image Classification</a>]</li>
                                <p>EN: English, ZH: Chinese, JP: Japanese, Ar: Arabic, IT: Italian</p>
                                <table>
                                    <thead>
                                        <tr>
                                            <th>method</th>
                                            <th>IN-1K (EN)</th>
                                            <th>IN-1K (ZH)</th>
                                            <th>IN-1K (JP)</th>
                                            <th>IN-1K (AR)</th>
                                            <th>IN-1K (IT)</th>
                                        </tr>
                                    </thead>
                                    <tbody>
                                        <tr>
                                            <td>Taiyi-CLIP-ViT-H</td>
                                            <td>-</td>
                                            <td>54.4</td>
                                            <td>-</td>
                                            <td>-</td>
                                            <td>-</td>
                                        </tr>
                                        <tr>
                                            <td>WuKong-ViT-L-G</td>
                                            <td>-</td>
                                            <td>57.5</td>
                                            <td>-</td>
                                            <td>-</td>
                                            <td>-</td>
                                        </tr>
                                        <tr>
                                            <td>CN-CLIP-ViT-H</td>
                                            <td>-</td>
                                            <td>59.6</td>
                                            <td>-</td>
                                            <td>-</td>
                                            <td>-</td>
                                        </tr>
                                        <tr>
                                            <td>AltCLIP-ViT-L</td>
                                            <td>74.5</td>
                                            <td>59.6</td>
                                            <td>-</td>
                                            <td>-</td>
                                            <td>-</td>
                                        </tr>
                                        <tr>
                                            <td>EVA-02-CLIP-E+</td>
                                            <td>82.0</td>
                                            <td>-</td>
                                            <td>-</td>
                                            <td>-</td>
                                            <td>41.2</td>
                                        </tr>
                                        <tr>
                                            <td>OpenCLIP-XLM-R-H</td>
                                            <td>77.0</td>
                                            <td>55.7</td>
                                            <td>53.1</td>
                                            <td>37.0</td>
                                            <td>56.8</td>
                                        </tr>
                                        <tr>
                                            <td>InternVL-C (ours)</td>
                                            <td>83.2</td>
                                            <td>64.5</td>
                                            <td>61.5</td>
                                            <td>44.9</td>
                                            <td>65.7</td>
                                        </tr>
                                    </tbody>
                                </table>
                                <li>Zero-Shot Video Classification</li>
                                <table>
                                    <thead>
                                        <tr>
                                            <th>method</th>
                                            <th>#frame</th>
                                            <th>K400</th>
                                            <th>K600</th>
                                            <th>K700</th>
                                        </tr>
                                    </thead>
                                    <tbody>
                                        <tr>
                                            <td>OpenCLIP-G</td>
                                            <td>1</td>
                                            <td>65.9</td>
                                            <td>66.1</td>
                                            <td>59.2</td>
                                        </tr>
                                        <tr>
                                            <td>EVA-02-CLIP-E+</td>
                                            <td>1</td>
                                            <td>69.8</td>
                                            <td>69.3</td>
                                            <td>63.4</td>
                                        </tr>
                                        <tr>
                                            <td>InternVL-C (ours)</td>
                                            <td>1</td>
                                            <td>71.0</td>
                                            <td>71.3</td>
                                            <td>65.7</td>
                                        </tr>
                                        <tr>
                                            <td>ViCLIP</td>
                                            <td>8</td>
                                            <td>75.7</td>
                                            <td>73.5</td>
                                            <td>66.4</td>
                                        </tr>
                                        <tr>
                                            <td>InternVL-C (ours)</td>
                                            <td>8</td>
                                            <td>79.4</td>
                                            <td>78.8</td>
                                            <td>71.5</td>
                                        </tr>
                                    </tbody>
                                </table>
                            </ul>
                        </details>

                        <details>
                            <summary>Cross-Modal Retrieval (click to expand)</summary>
                            <ul>
                                <li>English Zero-Shot Image-Text Retrieval</li>
                                <table>
                                    <thead>
                                        <tr>
                                            <td rowspan="3" align="left"><b>model</b></td>
                                            <td colspan="6" align="center"><b>Flickr30K</b></td>
                                            <td colspan="6" align="center"><b>COCO</b></td>
                                            <td rowspan="3" align="center"><b>avg</b></td>
                                        </tr>
                                        <tr align="center">
                                            <td colspan="3" align="center"><b>image-to-text</b></td>
                                            <td colspan="3" align="center"><b>text-to-image</b></td>
                                            <td colspan="3" align="center"><b>image-to-text</b></td>
                                            <td colspan="3" align="center"><b>text-to-image</b></td>
                                        </tr>
                                        <tr>
                                            <td>R@1</td>
                                            <td>R@5</td>
                                            <td>R@10</td>
                                            <td>R@1</td>
                                            <td>R@5</td>
                                            <td>R@10</td>
                                            <td>R@1</td>
                                            <td>R@5</td>
                                            <td>R@10</td>
                                            <td>R@1</td>
                                            <td>R@5</td>
                                            <td>R@10</td>
                                        </tr>
                                    </thead>
                                    <tbody>
                                        <tr align="center">
                                            <td align="left">OpenCLIP-G</td>
                                            <td>92.9</td>
                                            <td>99.3</td>
                                            <td>99.8</td>
                                            <td>79.5</td>
                                            <td>95.0</td>
                                            <td>97.1</td>
                                            <td>67.3</td>
                                            <td>86.9</td>
                                            <td>92.6</td>
                                            <td>51.4</td>
                                            <td>74.9</td>
                                            <td>83.0</td>
                                            <td>85.0</td>
                                        </tr>
                                        <tr align="center">
                                            <td align="left">EVA-02-CLIP-E+</td>
                                            <td>93.9</td>
                                            <td>99.4</td>
                                            <td>99.8</td>
                                            <td>78.8</td>
                                            <td>94.2</td>
                                            <td>96.8</td>
                                            <td>68.8</td>
                                            <td>87.8</td>
                                            <td>92.8</td>
                                            <td>51.1</td>
                                            <td>75.0</td>
                                            <td>82.7</td>
                                            <td>85.1</td>
                                        </tr>
                                        <tr align="center">
                                            <td align="left">EVA-CLIP-8B</td>
                                            <td>95.6</td>
                                            <td>99.6</td>
                                            <td>99.9</td>
                                            <td>80.8</td>
                                            <td>95.5</td>
                                            <td>97.6</td>
                                            <td>70.3</td>
                                            <td>89.3</td>
                                            <td>93.9</td>
                                            <td>53.0</td>
                                            <td>76.0</td>
                                            <td>83.4</td>
                                            <td>86.2</td>
                                        </tr>
                                        <tr align="center">
                                            <td align="left">InternVL-C (ours)</td>
                                            <td>94.7</td>
                                            <td>99.6</td>
                                            <td>99.9</td>
                                            <td>81.7</td>
                                            <td>96.0</td>
                                            <td>98.2</td>
                                            <td>70.6</td>
                                            <td>89.0</td>
                                            <td>93.5</td>
                                           

 <td>54.1</td>
                                            <td>77.3</td>
                                            <td>84.6</td>
                                            <td>86.6</td>
                                        </tr>
                                        <tr align="center">
                                            <td align="left">InternVL-G (ours)</td>
                                            <td>95.7</td>
                                            <td>99.7</td>
                                            <td>99.9</td>
                                            <td>85.0</td>
                                            <td>97.0</td>
                                            <td>98.6</td>
                                            <td>74.9</td>
                                            <td>91.3</td>
                                            <td>95.2</td>
                                            <td>58.6</td>
                                            <td>81.3</td>
                                            <td>88.0</td>
                                            <td>88.8</td>
                                        </tr>
                                    </tbody>
                                </table>
                                <li>Chinese Zero-Shot Image-Text Retrieval</li>
                                <table>
                                    <thead>
                                        <tr>
                                            <td rowspan="3" align="left"><b>model</b></td>
                                            <td colspan="6" align="center"><b>Flickr30K-CN</b></td>
                                            <td colspan="6" align="center"><b>COCO-CN</b></td>
                                            <td rowspan="3" align="center"><b>avg</b></td>
                                        </tr>
                                        <tr align="center">
                                            <td colspan="3" align="center"><b>image-to-text</b></td>
                                            <td colspan="3" align="center"><b>text-to-image</b></td>
                                            <td colspan="3" align="center"><b>image-to-text</b></td>
                                            <td colspan="3" align="center"><b>text-to-image</b></td>
                                        </tr>
                                        <tr>
                                            <td>R@1</td>
                                            <td>R@5</td>
                                            <td>R@10</td>
                                            <td>R@1</td>
                                            <td>R@5</td>
                                            <td>R@10</td>
                                            <td>R@1</td>
                                            <td>R@5</td>
                                            <td>R@10</td>
                                            <td>R@1</td>
                                            <td>R@5</td>
                                            <td>R@10</td>
                                        </tr>
                                    </thead>
                                    <tbody>
                                        <tr align="center">
                                            <td align="left">CN-CLIP-ViT-H</td>
                                            <td>81.6</td>
                                            <td>97.5</td>
                                            <td>98.8</td>
                                            <td>71.2</td>
                                            <td>91.4</td>
                                            <td>95.5</td>
                                            <td>63.0</td>
                                            <td>86.6</td>
                                            <td>92.9</td>
                                            <td>69.2</td>
                                            <td>89.9</td>
                                            <td>96.1</td>
                                            <td>86.1</td>
                                        </tr>
                                        <tr align="center">
                                            <td align="left">OpenCLIP-XLM-R-H</td>
                                            <td>86.1</td>
                                            <td>97.5</td>
                                            <td>99.2</td>
                                            <td>71.0</td>
                                            <td>90.5</td>
                                            <td>94.9</td>
                                            <td>70.0</td>
                                            <td>91.5</td>
                                            <td>97.0</td>
                                            <td>66.1</td>
                                            <td>90.8</td>
                                            <td>96.0</td>
                                            <td>87.6</td>
                                        </tr>
                                        <tr align="center">
                                            <td align="left">InternVL-C (ours)</td>
                                            <td>90.3</td>
                                            <td>98.8</td>
                                            <td>99.7</td>
                                            <td>75.1</td>
                                            <td>92.9</td>
                                            <td>96.4</td>
                                            <td>68.8</td>
                                            <td>92.0</td>
                                            <td>96.7</td>
                                            <td>68.9</td>
                                            <td>91.9</td>
                                            <td>96.5</td>
                                            <td>89.0</td>
                                        </tr>
                                        <tr align="center">
                                            <td align="left">InternVL-G (ours)</td>
                                            <td>92.9</td>
                                            <td>99.4</td>
                                            <td>99.8</td>
                                            <td>77.7</td>
                                            <td>94.8</td>
                                            <td>97.3</td>
                                            <td>71.4</td>
                                            <td>93.9</td>
                                            <td>97.7</td>
                                            <td>73.8</td>
                                            <td>94.4</td>
                                            <td>98.1</td>
                                            <td>90.9</td>
                                        </tr>
                                    </tbody>
                                </table>
                                <li>Multilingual Zero-Shot Image-Text Retrieval on XTD</li>
                                <table>
                                    <thead>
                                        <tr>
                                            <th>method</th>
                                            <th>EN</th>
                                            <th>ES</th>
                                            <th>FR</th>
                                            <th>ZH</th>
                                            <th>IT</th>
                                            <th>KO</th>
                                            <th>RU</th>
                                            <th>JP</th>
                                            <th>average</th>
                                        </tr>
                                    </thead>
                                    <tbody>
                                        <tr>
                                            <td>AltCLIP</td>
                                            <td>95.4</td>
                                            <td>94.1</td>
                                            <td>92.9</td>
                                            <td>95.1</td>
                                            <td>94.2</td>
                                            <td>94.4</td>
                                            <td>91.8</td>
                                            <td>91.7</td>
                                            <td>93.7</td>
                                        </tr>
                                        <tr>
                                            <td>OpenCLIP-XLM-R-H</td>
                                            <td>97.3</td>
                                            <td>96.1</td>
                                            <td>94.5</td>
                                            <td>94.7</td>
                                            <td>96.0</td>
                                            <td>90.2</td>
                                            <td>93.9</td>
                                            <td>94.0</td>
                                            <td>94.6</td>
                                        </tr>
                                        <tr>
                                            <td>InternVL-C (ours)</td>
                                            <td>97.3</td>
                                            <td>95.7</td>
                                            <td>95.1</td>
                                            <td>95.6</td>
                                            <td>96.0</td>
                                            <td>92.2</td>
                                            <td>93.3</td>
                                            <td>95.5</td>
                                            <td>95.1</td>
                                        </tr>
                                        <tr>
                                            <td>InternVL-G (ours)</td>
                                            <td>98.6</td>
                                            <td>97.7</td>
                                            <td>96.5</td>
                                            <td>96.7</td>
                                            <td>96.9</td>
                                            <td>95.1</td>
                                            <td>94.8</td>
                                            <td>96.1</td>
                                            <td>96.6</td>
                                        </tr>
                                    </tbody>
                                </table>
                            </ul>
                        </details>

                        <details>
                            <summary>Multimodal Dialogue (click to expand)</summary>
                            <ul>
                                <li>Zero-Shot Image Captioning</li>
                                <table>
                                    <thead>
                                        <tr>
                                            <th>method</th>
                                            <th>COCO</th>
                                            <th>Flickr30K</th>
                                            <th>NoCaps</th>
                                        </tr>
                                    </thead>
                                    <tbody>
                                        <tr>
                                            <td>Emu-I</td>
                                            <td>117.7</td>
                                            <td>-</td>
                                            <td>-</td>
                                        </tr>
                                        <tr>
                                            <td>DreamLLM</td>
                                            <td>115.4</td>
                                            <td>-</td>
                                            <td>-</td>
                                        </tr>
                                        <tr>
                                            <td>InternVL-G (ours)</td>
                                            <td>128.2</td>
                                            <td>79.2</td>
                                            <

td>113.7</td>
                                        </tr>
                                    </tbody>
                                </table>
                                <li>Multimodal Benchmarks with Frozen LLM</li>
                                <table>
                                    <thead>
                                        <tr>
                                            <th>method</th>
                                            <th>visual encoder</th>
                                            <th>glue layer</th>
                                            <th>LLM</th>
                                            <th>res.</th>
                                            <th>COCO</th>
                                            <th>Flickr</th>
                                            <th>NoCaps</th>
                                            <th>VQAv2</th>
                                            <th>GQA</th>
                                            <th>VizWiz</th>
                                            <th>TextVQA</th>
                                            <th>MME</th>
                                            <th>POPE</th>
                                        </tr>
                                    </thead>
                                    <tbody>
                                        <tr>
                                            <td>InstructBLIP</td>
                                            <td>EVA-g</td>
                                            <td>QFormer</td>
                                            <td>V-7B</td>
                                            <td>224</td>
                                            <td>–</td>
                                            <td>82.4</td>
                                            <td>123.1</td>
                                            <td>–</td>
                                            <td>49.2</td>
                                            <td>34.5</td>
                                            <td>50.1</td>
                                            <td>–</td>
                                            <td>–</td>
                                        </tr>
                                        <tr>
                                            <td>BLIP-2</td>
                                            <td>EVA-g</td>
                                            <td>QFormer</td>
                                            <td>V-13B</td>
                                            <td>224</td>
                                            <td>–</td>
                                            <td>71.6</td>
                                            <td>103.9</td>
                                            <td>41.0</td>
                                            <td>41.0</td>
                                            <td>19.6</td>
                                            <td>42.5</td>
                                            <td>1293.8</td>
                                            <td>85.3</td>
                                        </tr>
                                        <tr>
                                            <td>InstructBLIP</td>
                                            <td>EVA-g</td>
                                            <td>QFormer</td>
                                            <td>V-13B</td>
                                            <td>224</td>
                                            <td>–</td>
                                            <td>82.8</td>
                                            <td>121.9</td>
                                            <td>–</td>
                                            <td>49.5</td>
                                            <td>33.4</td>
                                            <td>50.7</td>
                                            <td>1212.8</td>
                                            <td>78.9</td>
                                        </tr>
                                        <tr>
                                            <td>InternVL-Chat (ours)</td>
                                            <td>IViT-6B</td>
                                            <td>QLLaMA</td>
                                            <td>V-7B</td>
                                            <td>224</td>
                                            <td>141.4</td>
                                            <td>89.7</td>
                                            <td>120.5</td>
                                            <td>72.3</td>
                                            <td>57.7</td>
                                            <td>44.5</td>
                                            <td>42.1</td>
                                            <td>1298.5</td>
                                            <td>85.2</td>
                                        </tr>
                                        <tr>
                                            <td>InternVL-Chat (ours)</td>
                                            <td>IViT-6B</td>
                                            <td>QLLaMA</td>
                                            <td>V-13B</td>
                                            <td>224</td>
                                            <td>142.4</td>
                                            <td>89.9</td>
                                            <td>123.1</td>
                                            <td>71.7</td>
                                            <td>59.5</td>
                                            <td>54.0</td>
                                            <td>49.1</td>
                                            <td>1317.2</td>
                                            <td>85.4</td>
                                        </tr>
                                    </tbody>
                                </table>
                                <li>Multimodal Benchmarks with Trainable LLM</li>
                                <table>
                                    <thead>
                                        <tr>
                                            <th>method</th>
                                            <th>vision encoder</th>
                                            <th>LLM</th>
                                            <th>res.</th>
                                            <th>VQAv2</th>
                                            <th>GQA</th>
                                            <th>VizWiz</th>
                                            <th>SQA</th>
                                            <th>TextVQA</th>
                                            <th>POPE</th>
                                            <th>MME</th>
                                            <th>MMB</th>
                                            <th>MMB<sub>CN</sub></th>
                                            <th>MMVet</th>
                                        </tr>
                                    </thead>
                                    <tbody>
                                        <tr>
                                            <td>LLaVA-1.5</td>
                                            <td>CLIP-L-336px</td>
                                            <td>V-7B</td>
                                            <td>336</td>
                                            <td>78.5</td>
                                            <td>62.0</td>
                                            <td>50.0</td>
                                            <td>66.8</td>
                                            <td>58.2</td>
                                            <td>85.9</td>
                                            <td>1510.7</td>
                                            <td>64.3</td>
                                            <td>58.3</td>
                                            <td>30.5</td>
                                        </tr>
                                        <tr>
                                            <td>LLaVA-1.5</td>
                                            <td>CLIP-L-336px</td>
                                            <td>V-13B</td>
                                            <td>336</td>
                                            <td>80.0</td>
                                            <td>63.3</td>
                                            <td>53.6</td>
                                            <td>71.6</td>
                                            <td>61.3</td>
                                            <td>85.9</td>
                                            <td>1531.3</td>
                                            <td>67.7</td>
                                            <td>63.6</td>
                                            <td>35.4</td>
                                        </tr>
                                        <tr>
                                            <td>InternVL-Chat (ours)</td>
                                            <td>IViT-6B-224px</td>
                                            <td>V-7B</td>
                                            <td>336</td>
                                            <td>79.3</td>
                                            <td>62.9</td>
                                            <td>52.5</td>
                                            <td>66.2</td>
                                            <td>57.0</td>
                                            <td>86.4</td>
                                            <td>1525.1</td>
                                            <td>64.6</td>
                                            <td>57.6</td>
                                            <td>31.2</td>
                                        </tr>
                                        <tr>
                                            <td>InternVL-Chat (ours)</td>
                                            <td>IViT-6B-224px</td>
                                            <td>V-13B</td>
                                            <td>336</td>
                                            <td>80.2</td>
                                            <td>63.9</td>
                                            <td>54.6</td>
                                            <td>70.1</td>
                                            <td>58.7</td>
                                            <td>87.1</td>
                                            <td>1546.9</td>
                                            <td>66.5</td>
                                            <td>61.9</td>
                                            <td>33.7</td>
                                        </tr>
                                        <tr>
                                            <td>InternVL-Chat (ours)</td>
                                            <td>IViT-6B-448px</td>
                                            <td>V-13B</td>
                                            <td>448</td>
                                            <td>82.0</td>
                                            <td>64.1</td>
                                            <td>60.1</td>
                                            <td>71.6</td>
                                            <td>64.8</td>
                                            <td>87.2</td>
                                            <td>1579.0</td>
                                            <td>68.2</td>
                                            <td>64.0</td>
                                            <td>36.7</td>
                                        </tr>
                                    </tbody>
                                </table>
                                <li>Tiny LVLM [<a href="https://github.com/OpenGVLab/Multi-Modality-Arena/tree/main/tiny_lvlm_evaluation">see details</a>]</li>
                                <table>
                                    <thead>
                                        <tr>
                                            <th>Rank</th>
                                            <th>Model</th>
                                            <th>Version</th>
                                            <th>Score</th>
                                        </tr>
                                    </thead>
                                    <tbody>
                                        <tr>
                                            <td>🏅️</td>
                                            <td><a href="https://github.com/Open

GVLab/InternVL"><strong>InternVL</strong></a></td>
                                            <td>InternVL-Chat</td>
                                            <td><strong>327.61</strong></td>
                                        </tr>
                                        <tr>
                                            <td>🥈</td>
                                            <td><a href="https://github.com/InternLM/InternLM-XComposer"><strong>InternLM-XComposer-VL</strong></a></td>
                                            <td>InternLM-XComposer-VL-7B</td>
                                            <td><strong>322.51</strong></td>
                                        </tr>
                                        <tr>
                                            <td>🥉</td>
                                            <td><a href="https://bard.google.com/"><strong>Bard</strong></a></td>
                                            <td>Bard</td>
                                            <td><strong>319.59</strong></td>
                                        </tr>
                                        <tr>
                                            <td>4</td>
                                            <td><a href="https://github.com/QwenLM/Qwen-VL">Qwen-VL-Chat</a></td>
                                            <td>Qwen-VL-Chat</td>
                                            <td>316.81</td>
                                        </tr>
                                        <tr>
                                            <td>5</td>
                                            <td><a href="https://github.com/haotian-liu/LLaVA">LLaVA-1.5</a></td>
                                            <td>Vicuna-7B</td>
                                            <td>307.17</td>
                                        </tr>
                                        <tr>
                                            <td>6</td>
                                            <td><a href="https://github.com/salesforce/LAVIS/tree/main/projects/instructblip">InstructBLIP</a></td>
                                            <td>Vicuna-7B</td>
                                            <td>300.64</td>
                                        </tr>
                                        <tr>
                                            <td>7</td>
                                            <td><a href="https://github.com/InternLM/InternLM-XComposer">InternLM-XComposer</a></td>
                                            <td>InternLM-XComposer-7B</td>
                                            <td>288.89</td>
                                        </tr>
                                        <tr>
                                            <td>8</td>
                                            <td><a href="https://github.com/salesforce/LAVIS/tree/main/projects/blip2">BLIP2</a></td>
                                            <td>FlanT5xl</td>
                                            <td>284.72</td>
                                        </tr>
                                        <tr>
                                            <td>9</td>
                                            <td><a href="https://github.com/mlpc-ucsd/BLIVA">BLIVA</a></td>
                                            <td>Vicuna-7B</td>
                                            <td>284.17</td>
                                        </tr>
                                        <tr>
                                            <td>10</td>
                                            <td><a href="https://github.com/bytedance/lynx-llm">Lynx</a></td>
                                            <td>Vicuna-7B</td>
                                            <td>279.24</td>
                                        </tr>
                                    </tbody>
                                </table>
                            </ul>
                        </details>
                    </div>
                </article>
            </div>
        </main>
        <footer class="site-footer h-card">
            <data class="u-url" href="https://internvl.github.io/blog/">InternVL</data>
            <p class="footer-colophon">
                <a href="https://internvl.github.io/blog/2024-05-15-InternVL/">InternVL-1.5</a> • <a href="https://internvl.github.io/blog/2024-05-20-Mini-InternVL/">Mini-InternVL</a>
            </p>
        </footer>
    </body>
</html>

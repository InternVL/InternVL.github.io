<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <!-- Begin Jekyll SEO tag v2.8.0 -->
        <title>InternVL: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks</title>
        <meta name="generator" content="Jekyll v3.9.4"/>
        <meta property="og:title" content="InternVL: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks"/>
        <meta name="author" content="chenzhe"/>
        <meta property="og:locale" content="en_US"/>
        <meta name="description" content="ld knowledge. LLaVA-NeXT even exceeds Gemini Pro on several benchmarks."/>
        <meta property="og:description" content="LLaVA team presents LLaVA-NeXT, with improved reasoning, OCR, and world knowledge. LLaVA-NeXT even exceeds Gemini Pro on several benchmarks."/>
        <link rel="canonical" href="/2023-12-12-InternVL-1.0/"/>
        <meta property="og:url" content="/2023-12-12-InternVL-1.0/"/>
        <meta property="og:site_name" content="InternVL"/>
        <meta property="og:type" content="article"/>
        <meta property="article:published_time" content="2024-01-30T12:33:38-06:00"/>
        <meta name="twitter:card" content="summary"/>
        <meta property="twitter:title" content="InternVL: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks"/>
        <script type="application/ld+json">
            {
                "@context": "https://schema.org",
                "@type": "BlogPosting",
                "author": {
                    "@type": "Person",
                    "name": "chenzhe"
                },
                "dateModified": "2024-01-30T12:33:38-06:00",
                "datePublished": "2024-01-30T12:33:38-06:00",
                "description": "InternVL 1.0-1.3: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks",
                "headline": "InternVL 1.0-1.3: Scaling up Vision Foundation Models and Aligning for Generic Visual-Linguistic Tasks",
                "mainEntityOfPage": {
                    "@type": "WebPage",
                    "@id": "https://internvl.github.io/blog/2024-05-10-InternVL/"
                },
                "url": "https://internvl.github.io/blog/2024-05-10-InternVL/"
            }</script>
        <!-- End Jekyll SEO tag -->
        <link rel="stylesheet" href="/blog/assets/main.css">
        <link type="application/atom+xml" rel="alternate" href="https://llava-vl.github.io/blog/feed.xml" title="LLaVA"/>
    </head>
    <body>
        <header class="site-header" role="banner">
            <div class="wrapper">
                <a class="site-title" rel="author" href="/blog/">InternVL</a>
                <nav class="site-nav">
                    <input type="checkbox" id="nav-trigger" class="nav-trigger"/>
                    <label for="nav-trigger">
                        <span class="menu-icon">
                            <svg viewBox="0 0 18 15" width="18px" height="15px">
                                <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
                            </svg>
                        </span>
                    </label>
                    <div class="trigger"></div>
                </nav>
            </div>
        </header>
        <main class="page-content" aria-label="Content">
            <div class="wrapper">
                <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
                    <header class="post-header">
                        <h1 class="post-title p-name" itemprop="name headline">InternVL 1.1: Enhance Chinese and OCR Capabilities</h1>
                        <p class="post-meta">
                            <time class="dt-published" datetime="2024-01-30T12:33:38-06:00" itemprop="datePublished">2024/01/24
      </time>
                            •
                            <span itemprop="author" itemscope itemtype="http://schema.org/Person">
                                <span class="p-author h-card" itemprop="name">Zhe Chen, Wenhai Wang, Xizhou Zhu, Lewei Lu, Tong Lu, Yu Qiao, Jifeng Dai
                                </span>
                            </span>
                        </p>
                    </header>
                    <div class="post-content e-content" itemprop="articleBody">
                        <!-- 插入Markdown转换后的HTML内容 -->

                        <p>We released <a href="https://huggingface.co/OpenGVLab/InternVL-Chat-V1-1">InternVL-Chat-V1.1</a>, featuring a structure similar to LLaVA, including a ViT, an MLP projector, and an LLM. In this version, we explored increasing the resolution to 448x448, enhancing OCR capabilities, and improving support for Chinese conversations. Below is an example of the improved capabilities.</p>

                        <h2 id="model-card">Model Card</h2>

                        <table>
                          <tr><th colspan="2">Name</th><th>LLaVA-NeXT-7B</th><th>LLaVA-NeXT-13B</th><th>LLaVA-NeXT-34B</th></tr>
                          <tr><th rowspan="4">Model Size</th><td>Total</td><td><b>7.06B</b></td><td><b>13.35B</b></td><td><b>34.75B</b></td></tr>
                          <tr><td>Vision Encoder</td><td>303.5M</td><td>303.5M</td><td>303.5M</td></tr>
                          <tr><td>Connector</td><td>21M</td><td>31.5M</td><td>58.7M</td></tr>
                          <tr><td>LLM</td><td>6.74B</td><td>13B</td><td>34.39B</td></tr>
                          <tr><th colspan="2">Resolution</th><td colspan="3">336 x [(2,2), (1,2), (2,1), (1,3), (3,1), (1,4), (4,1)]</td></tr>
                          <tr><th>Stage-1</th><th>Training Data</th><td colspan="3">558K</td></tr>
                          <tr><th></th><th>Trainable Module</th><td colspan="3">Connector</td></tr>
                          <tr><th>Stage-2</th><th>Training Data</th><td colspan="3">760K</td></tr>
                          <tr><th></th><th>Trainable Module</th><td colspan="3">Full model</td></tr>
                          <tr><th colspan="2">Compute (#GPU x #Hours)</th><td>8x20</td><td>16x24</td><td>32x30</td></tr>
                          <tr><th colspan="2">Training Data (#Samples)</th><td colspan="3">1318K</td></tr>
                        </table>
                        <p><img width="650" alt="image" src="images/Intern1_2_2.png"></p>

                    </div>
                </article>
            </div>
        </main>
        <footer class="site-footer h-card">
        <!--   <data class="u-url" href="https://internvl.github.io/blog/">InternVL</data>--> 
            <p class="footer-colophon">
                <a href="https://internvl.github.io/blog/">InternVL</a> <br>
                <a href="https://internvl.github.io/blog/2024-05-15-InternVL/">InternVL-1.5</a> <br>
                <a href="https://internvl.github.io/blog/2024-05-20-Mini-InternVL/">Mini-InternVL</a>
            </p>
        </footer>
    </body>
</html>

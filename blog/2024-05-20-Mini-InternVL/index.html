<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <!-- Begin Jekyll SEO tag v2.8.0 -->
        <title>Mini InternVL: lightning-fast performance</title>
        <meta name="generator" content="Jekyll v3.9.4"/>
        <meta property="og:title" content="Mini InternVL: lightning-fast performance"/>
        <meta name="author" content="chenzhe"/>
        <meta property="og:locale" content="en_US"/>
        <meta name="description" content="LLaVA team presents LLaVA-NeXT, with improved reasoning, OCR, and world knowledge. LLaVA-NeXT even exceeds Gemini Pro on several benchmarks."/>
        <meta property="og:description" content="LLaVA team presents LLaVA-NeXT, with improved reasoning, OCR, and world knowledge. LLaVA-NeXT even exceeds Gemini Pro on several benchmarks."/>
        <link rel="canonical" href="https://internvl.github.io/blog/2024-05-20-Mini-InternVL/"/>
        <meta property="og:url" content="https://internvl.github.io/blog/2024-05-20-Mini-InternVL/"/>
        <meta property="og:site_name" content="InternVL"/>
        <meta property="og:type" content="article"/>
        <meta property="article:published_time" content="2024-01-30T12:33:38-06:00"/>
        <meta name="twitter:card" content="summary"/>
        <meta property="twitter:title" content="LLaVA-NeXT: Improved reasoning, OCR, and world knowledge"/>
        <script type="application/ld+json">
            {
                "@context": "https://schema.org",
                "@type": "BlogPosting",
                "author": {
                    "@type": "Person",
                    "name": "chenzhe"
                },
                "dateModified": "2024-01-30T12:33:38-06:00",
                "datePublished": "2024-01-30T12:33:38-06:00",
                "description": "Mini InternVL: lightning-fast performance",
                "headline": "Mini InternVL: lightning-fast performance",
                "mainEntityOfPage": {
                    "@type": "WebPage",
                    "@id": "https://internvl.github.io/blog/2024-05-20-Mini-InternVL/"
                },
                "url": "https://internvl.github.io/blog/2024-05-20-Mini-InternVL/"
            }</script>
        <!-- End Jekyll SEO tag -->
        <link rel="stylesheet" href="/blog/assets/main.css">
        <link type="application/atom+xml" rel="alternate" href="https://llava-vl.github.io/blog/feed.xml" title="LLaVA"/>
    </head>
    <body>
        <header class="site-header" role="banner">
            <div class="wrapper">
                <a class="site-title" rel="author" href="/blog/">InternVL</a>
                <nav class="site-nav">
                    <input type="checkbox" id="nav-trigger" class="nav-trigger"/>
                    <label for="nav-trigger">
                        <span class="menu-icon">
                            <svg viewBox="0 0 18 15" width="18px" height="15px">
                                <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
                            </svg>
                        </span>
                    </label>
                    <div class="trigger"></div>
                </nav>
            </div>
        </header>
        <main class="page-content" aria-label="Content">
            <div class="wrapper">
                <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
                    <header class="post-header">
                        <h1 class="post-title p-name" itemprop="name headline">Mini-InternVL (2.1B)</h1>
                        <p class="post-meta">
                            <time class="dt-published" datetime="2024-05-20" itemprop="datePublished">May 20, 2024</time>
                            • 
                            <span itemprop="author" itemscope itemtype="http://schema.org/Person">
                                <span class="p-author h-card" itemprop="name">Zhe Chen, Weiyun Wang, Wenhai Wang, Erfei Cui, Zhangwei Gao, Xizhou Zhu, Lewei Lu, Tong Lu, Yu Qiao, Jifeng Dai</span>
                            </span>
                        </p>
                    </header>
                    <div class="post-content e-content" itemprop="articleBody">
                        <p>We are excited to introduce Mini-InternVL-Chat. In the era of large global models, many researchers have started to focus on smaller models, such as Gemma-2B and Qwen-1.8B. Inspired by their efforts, we have distilled our vision foundation model <a href="https://huggingface.co/OpenGVLab/InternViT-6B-448px-V1-2">InternViT-6B</a> down to 300M and used InternLM-1.8B as our language model. This resulted in a small model with excellent performance.</p>
                        <img width="650" alt="image" src="images/mini.png">
    
                        <p>From the experimental results, we've observed that a smaller language model (1.8B) is well-suited for our smaller vision model (InternViT-300M). This combination maximizes efficiency while maintaining impressive performance across various benchmarks, demonstrating the effectiveness of small models in handling complex tasks.</p>
    
                        <p>For better training reproducibility, our training process remains consistent with our InternVL 1.5 model. The data and methodologies used are also largely aligned with those of InternVL 1.5. To reduce training costs, we provide a pre-trained MLP projector and employ around 1 million visual instruction tuning samples for SFT. Our model has a total of 2.1 billion parameters and can be trained within 1 day using 16 A100 GPUs. The code, data, and model will be made publicly available.</p>
    
                        <h3>Data Preparation</h3>
                        <p>Inspired by InternVL 1.5, we adopted a data-efficient SFT strategy to train Mini-InternVL-Chat, utilizing approximately 1.2M of visual instruction tuning samples in total, all of which are fully open-source. In a macro sense, we build upon <a href="https://github.com/InternLM/InternLM-XComposer/blob/main/projects/ShareGPT4V/docs/Data.md#prepare-images">ShareGPT-4V</a> and additionally integrate <a href="https://huggingface.co/datasets/openbmb/llava_zh">LLaVA-ZH</a>, <a href="https://github.com/kushalkafle/DVQA_dataset">DVQA</a>, <a href="https://github.com/vis-nlp/ChartQA">ChartQA</a>, <a href="https://allenai.org/data/diagrams">AI2D</a>, <a href="https://www.docvqa.org/datasets">DocVQA</a>, <a href="https://github.com/SCNU203/GeoQA-Plus">GeoQA+</a>, and <a href="https://huggingface.co/datasets/naver-clova-ix/synthdog-en">SynthDoG-EN</a>. Most of the data remains consistent with InternVL 1.5.</p>
                        <p>For more details about data preparation, please see <a href="./internvl_chat#prepare-training-datasets">here</a>.</p>
    
                        <h3>Performance</h3>
                        <p><em>Proprietary Model</em></p>
                        <table>
                            <thead>
                                <tr>
                                    <th>model</th>
                                    <th>open-source</th>
                                    <th>#param</th>
                                    <th>DocVQA</th>
                                    <th>ChartQA</th>
                                    <th>InfoVQA</th>
                                    <th>TextVQA</th>
                                    <th>OCRBench</th>
                                    <th>MME</th>
                                    <th>RWQA</th>
                                    <th>AI2D</th>
                                    <th>MMMU</th>
                                    <th>MMB-EN/CN</th>
                                    <th>CCB</th>
                                    <th>MMVet</th>
                                    <th>SEED</th>
                                    <th>HallB</th>
                                    <th>MathVista</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>GPT-4V</td>
                                    <td>✗</td>
                                    <td>-</td>
                                    <td>88.4</td>
                                    <td>78.5</td>
                                    <td>-</td>
                                    <td>78.0</td>
                                    <td>645</td>
                                    <td>1926.6</td>
                                    <td>61.4</td>
                                    <td>78.2</td>
                                    <td>56.8</td>
                                    <td>77.0 / 74.4</td>
                                    <td>46.5</td>
                                    <td>67.6</td>
                                    <td>71.6</td>
                                    <td>46.5</td>
                                    <td>49.9</td>
                                </tr>
                                <tr>
                                    <td>Gemini Ultra 1.0</td>
                                    <td>✗</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>90.9</td>
                                    <td>80.3</td>
                                    <td>82.3</td>
                                    <td>-</td>
                                    <td>1933.4</td>
                                    <td>-</td>
                                    <td>79.5</td>
                                    <td>59.4</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>70.7</td>
                                    <td>-</td>
                                    <td>53.0</td>
                                </tr>
                                <tr>
                                    <td>Gemini Pro 1.0</td>
                                    <td>✗</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>84.1</td>
                                    <td>75.2</td>
                                    <td>74.6</td>
                                    <td>659</td>
                                    <td>2034.9</td>
                                    <td>-</td>
                                    <td>79.4</td>
                                    <td>59.7</td>
                                    <td>73.4 / 52.5</td>
                                    <td>64.3</td>
                                    <td>70.7</td>
                                    <td>70.7</td>
                                    <td>45.2</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Gemini Pro 1.5</td>
                                    <td>✗</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>81.4</td>
                                    <td>72.7</td>
                                    <td>73.5</td>
                                    <td>-</td>
                                    <td>1586.6</td>
                                    <td>49.8</td>
                                    <td>88.7</td>
                                    <td>59.4</td>
                                    <td>-</td>
                                    <td>52.8</td>
                                    <td>-</td>
                                    <td>72.4</td>
                                    <td>43.3</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Qwen-VL-Max</td>
                                    <td>✗</td>
                                    <td>-</td>
                                    <td>93.1</td>
                                    <td>79.9</td>
                                    <td>73.4</td>
                                    <td>-</td>
                                    <td>723</td>
                                    <td>2433.6</td>
                                    <td>57.3</td>
                                    <td>79.4</td>
                                    <td>51.3</td>
                                    <td>77.6 / 77.5</td>
                                    <td>63.5</td>
                                    <td>66.6</td>
                                    <td>-</td>
                                    <td>41.2</td>
                                    <td>51.0</td>
                                </tr>
                                <tr>
                                    <td>Qwen-VL-Plus</td>
                                    <td>✗</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>80.3</td>
                                    <td>73.9</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>2134.5</td>
                                    <td>54.9</td>
                                    <td>78.1</td>
                                    <td>59.4</td>
                                    <td>-</td>
                                    <td>58.1</td>
                                    <td>71.2</td>
                                    <td>72.7</td>
                                    <td>47.4</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Claude-3 Opus</td>
                                    <td>✗</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>1625.9</td>
                                    <td>51.9</td>
                                    <td>88.7</td>
                                    <td>59.7</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Claude-3 Sonnet</td>
                                    <td>✗</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>1453.2</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Claude-3 Haiku</td>
                                    <td>✗</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>2069.0</td>
                                    <td>49.4</td>
                                    <td>80.7</td>
                                    <td>59.4</td>
                                    <td>80.7 / 79.9</td>
                                    <td>71.2</td>
                                    <td>63.3</td>
                                    <td>70.4</td>
                                    <td>44.8</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>HPT Pro</td>
                                    <td>✗</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>2206.4</td>
                                    <td>-</td>
                                    <td>79.2</td>
                                    <td>49.9</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>MM1</td>
                                    <td>✗</td>
                                    <td>30B</td>
                                    <td>-</td>
                                    <td>68.7</td>
                                    <td>73.5</td>
                                    <td>-</td>
                                    <td>625</td>
                                    <td>68.7</td>
                                    <td>88.3</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>52.8</td>
                                </tr>
                                <tr>
                                    <td>Step-1V</td>
                                    <td>✗</td>
                                    <td>100B</td>
                                    <td>85.6</td>
                                    <td>76.1</td>
                                    <td>78.1</td>
                                    <td>-</td>
                                    <td>621</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Grok-1.5V</td>
                                    <td>✗</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>85.6</td>
                                    <td>76.1</td>
                                    <td>78.1</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>Text-Monkey</td>
                                    <td>✓</td>
                                    <td>10B</td>
                                    <td>82.0</td>
                                    <td>75.9</td>
                                    <td>28.6</td>
                                    <td>64.3</td>
                                    <td>561</td>
                                    <td>2028.0</td>
                                    <td>70.4</td>
                                    <td>51.1</td>
                                    <td>-</td>
                                    <td>81.1 / 79.0</td>
                                    <td>49.2</td>
                                    <td>-</td>
                                    <td>75.6</td>
                                    <td>-</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>DocOwl-1.5</td>
                                    <td>✓</td>
                                    <td>8B</td>
                                    <td>82.2</td>
                                    <td>70.7</td>
                                    <td>68.6</td>
                                    <td>-</td>
                                    <td>569</td>
                                    <td>2028.0</td>
                                    <td>70.4</td>
                                    <td>51.1</td>
                                    <td>-</td>
                                    <td>81.1 / 79.0</td>
                                    <td>49.2</td>
                                    <td>-</td>
                                    <td>75.6</td>
                                    <td>-</td>
                                    <td>-</td>
                                </tr>
                                <tr>
                                    <td>LLaVA-NeXT</td>
                                    <td>✓</td>
                                    <td>35B</td>
                                    <td>84.3</td>
                                    <td>68.7</td>
                                    <td>51.5</td>
                                    <td>69.5*</td>
                                    <td>574</td>
                                    <td>2175.4</td>
                                    <td>67.5</td>
                                    <td>79.0</td>
                                    <td>51.6</td>
                                    <td>82.1 / 82.0</td>
                                    <td>59.2</td>
                                    <td>75.6</td>
                                    <td>49.3</td>
                                    <td>47.7</td>
                                    <td>53.5</td>
                                </tr>
                                <tr>
                                    <td>InternVL 1.2</td>
                                    <td>✓</td>
                                    <td>40B</td>
                                    <td>57.7</td>
                                    <td>68.0</td>
                                    <td>39.5</td>
                                    <td>72.5*</td>
                                    <td>569</td>
                                    <td>2175.4</td>
                                    <td>67.5</td>
                                    <td>79.0</td>
                                    <td>51.6</td>
                                    <td>82.1 / 82.0</td>
                                    <td>59.2</td>
                                    <td>75.6</td>
                                    <td>49.3</td>
                                    <td>47.7</td>
                                    <td>53.5</td>
                                </tr>
                                <tr>
                                    <td>InternVL 1.5</td>
                                    <td>✓</td>
                                    <td>26B</td>
                                    <td>90.9</td>
                                    <td>83.8</td>
                                    <td>72.5</td>
                                    <td>80.6</td>
                                    <td>724</td>
                                    <td>2187.6</td>
                                    <td>66.0</td>
                                    <td>80.7</td>
                                    <td>45.2</td>
                                    <td>82.2 / 82.0</td>
                                    <td>69.8</td>
                                    <td>62.8</td>
                                    <td>76.0</td>
                                    <td>49.3</td>
                                    <td>53.5</td>
                                </tr>
                                <tr>
                                    <td>Mini-InternVL-Chat (ours)</td>
                                    <td>✓</td>
                                    <td>2.1B</td>
                                    <td>82.0</td>
                                    <td>72.8</td>
                                    <td>54.6</td>
                                    <td>71.1</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>-</td>
                                    <td>68.4</td>
                                    <td>35.0</td>
                                    <td>70.2 / 66.5</td>
                                    <td>67.3</td>
                                    <td>43.9</td>
                                    <td>6.9</td>
                                    <td>-</td>
                                    <td>-</td>
                                </tr>
                            </tbody>
                        </table>
                        <p>MMBench results are collected from the <a href="https://mmbench.opencompass.org.cn/leaderboard">leaderboard</a>.</p>
    
                        <h3>Training (SFT)</h3>
                        <p>We provide <a href="./internvl_chat/shell/hermes2_yi34b/internvl_chat_v1_2_hermes2_yi34b_448_res_finetune.sh">slurm scripts</a> for multi-node multi-GPU training. You can use either 32 or 64 GPUs to train this model. If you use 64 GPUs, training will take approximately 18 hours.</p>
    
                        <p>The hyperparameters used for finetuning are listed in the following table.</p>
                        <table>
                            <thead>
                                <tr>
                                    <th>Hyperparameter</th>
                                    <th>Trainable Param</th>
                                    <th>Global Batch Size</th>
                                    <th>Learning rate</th>
                                    <th>Epochs</th>
                                    <th>Max length</th>
                                    <th>Weight decay</th>
                                </tr>
                            </thead>
                            <tbody>
                                <tr>
                                    <td>Mini-InternVL-Chat</td>
                                    <td>40B (full model)</td>
                                    <td>512</td>
                                    <td>1e-5</td>
                                    <td>1</td>
                                    <td>2048</td>
                                    <td>0.05</td>
                                </tr>
                            </tbody>
                        </table>
                    </div>
                </article>
            </div>
        </main>
        <footer class="site-footer h-card">
            <data class="u-url" href="/blog/"></data>
            <div class="wrapper">
                <h2 class="footer-heading">InternVL</h2>
                <p class="footer-colophon">
                    <a href="https://internvl.github.io/blog/">InternVL</a><br>
                    <a href="https://internvl.github.io/blog/2024-05-10-InternVL/">InternVL 1.0-1.3</a><br>
                    <a href="https://internvl.github.io/blog/2024-05-15-InternVL/">InternVL-1.5</a>
                </p>
            </div>
        </footer>
    </body>
</html>
